<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8">
		<title>Формализация &mdash; &lambda;-calculus</title>

		<link rel="stylesheet" type="text/css" href="css/main.css">
		<link rel="stylesheet" type="text/css" href="css/highlighting.css">
	</head>
	<body>
		<h1><b>&lambda;</b>-calculus</h1>
		<h2>III. Формализация</h2>


		<nav>
			<a href="pt2.html">&leftarrow; II. Управление поведением</a>
			<a href="pt4.html">IV. Продвинутая арифметика &rightarrow;</a>
		</nav>


		<h3>Выражения</h3>

		<p>
			Функции и выражения так же называются термами. Термы состоят из объявлений &lambda;-функций (абстракций), применений &lambda;-функций (аппликаций), а также переменных.
		</p>

		<p>
			Если переменная относится к аргументу какой-то &lambda;-функции внутри терма, то такая переменная называется связанной. Иначе, если она не привязана к какой-либо &lambda;-функции в рассматриваемом терме, она называется свободной переменной.
		</p>

		<p>
			Особый интерес в &lambda;-исчислении представляют замкнутые термы (или комбинаторы). Комбинатор &mdash; терм, у которого нет свободных переменных, который не ссылается ни на что извне. Например, <code>\f. f x</code> &mdash; не комбинатор, а <code>\x. \f. f x</code> &mdash; комбинатор.
		</p>


		<h3>Порядок вычислений</h3>

		<p>
			Есть еще один важный вопрос, который мы не обсудили: в каком порядке применять &beta;-редукции. Очевидно (и доказывается), что если к какому-либо выражению попробовать в разном порядке применить &beta;-редукции для сведения его к &beta;-нормальной форме, то получится одно и то же (с точностью до названия переменных). Единственный вопрос &mdash; не уйдем ли мы в какой-то момент бесконечный цикл, и зависит ли это от порядка вычислений.
		</p>

		<p>
			Порядок вычислений проще всего представить себе так. Представьте, что вы пишете программу на каком-то классическом языке программирования, вроде C++ или Python, и у вас там написано <code>f(g())</code>. Тогда сначала вычислится значение <code>g()</code>, а затем результат подставится в качестве аргумента для <code>f</code>.
		</p>

		<p>
			А можно считать не так, а представить, что вы пытаетесь оптимизировать математическое выражение. Пусть, например, написано:
		</p>

		<pre>
x = 183972 * 32432
x - (x + 100) = ?
</pre>

		<p>
			Вряд ли вы будете вычислять сначала внутренние части: <code>x</code> и <code>x + 100</code>. Скорее всего, вы сначала раскроете все скобки и получите сразу <code>-100</code>.
		</p>

		<p>
			Порядок вычисления изнутри наружу, как в C++ и Python, называется аппликативным порядком. Он может быть эффективнее в том смысле, что все выражения сводятся к самой короткой форме, и для вычислений не нужно много памяти. Порядок вычисления снаружи внутрь, как в математическом примере, называется нормальным порядком. Он требует больше памяти, но у него есть и плюс.
		</p>

		<p>
			Попробуйте-ка вычислить такое выражение:
		</p>

		<pre>(\x. \y. y) ((\x. x x) (\x. x x)) 1</pre>

		<p>
			Нормальный порядок спокойно решает эту задачу такими &beta;-редукциями:
		</p>

		<pre>(\x. \y. y) ((\x. x x) (\x. x x)) 1 -> (\y. y) 1 -> 1</pre>

		<p>
			А аппликативный порядок? Раскрываем <code>(\x. x x) (\x. x x)</code> &mdash; это самое внутреннее нераскрытое выражение. Для наглядности переименую переменные: <code>(\x. x x) (\y. y y)</code>. Теперь подставим аргумент в качестве <code>x</code> слева: <code>(\y. y y) (\y. y y)</code>. Получилось то же самое &mdash; ой, бесконечный цикл.
		</p>

		<p>
			Вообще говоря, нормальный порядок потому и называется нормальным, что если это теоретически возможно, &beta;-нормальную форму он выдаст обязательно.
		</p>


		<h3>Сравнение выражений</h3>

		<p>
			Хотелось бы формально обсудить, как сравнивать выражения. Ну, то что <code>1 + 2 = 3</code> &mdash; мы знаем, а правда ли и что вообще означает запись <code>\x. sin (1 + 2) = \y. (\x. sin x) 3</code>?
		</p>

		<p>
			Чтобы раз и навсегда решить это вопрос, давайте различать следующие обозначения:
		</p>

		<ul>
			<li>
				<code>a = b</code> будет обозначать чисто математическое равенство.
			</li>

			<li>
				<p>
					<code>a -> b</code>, уже встречавшееся ранее, означает, что выражение <code>a</code> можно преобразовать в выражение <code>b</code>, последовательно применяя любые из трех уже знакомых нам операций: &alpha;-эквивалентность, &beta;-редукция, &eta;-преобразование. И пусть знак &beta; вас не путает &mdash; совместимость, что с ней поделать. Стрелка означает однонаправленность отношения. Например:
				</p>
				<pre>(\x. sin x) (3) -> sin 3</pre>
				<p>
					Но не:
				</p>
				<pre>sin 3 -> (\x. sin x) (3)</pre>
			</li>

			<li>
				<p>
					<code>a ->> b</code> означает то же самое, что <code>a -> b</code>, но еще требуется, чтобы <code>b</code> было &beta;-нормальной формой. Проще говоря, <code>a ->> ...</code> показывает, какой конечный результат будет при "выполнении" <code>a</code>. Если вам так проще &mdash; это рефлексивное транзитивное замыкание по трем основным преобразованиям. Например:
				</p>
				<pre>(\f. \x. \y. f x y) ->> (\f. f)</pre>
				<p>
					Но не:
				</p>
				<pre>(\f. \x. \y. f x y) ->> (\f. \x. f x)</pre>
			</li>

			<li>
				<p>
					<code>a =b b</code> означает, что выражение <code>a</code> можно преобразовать в выражение <code>b</code>, последовательно применяя любые из трех операций выше или обратные к ним. То есть, например:
				</p>
				<pre>(\x. sin x) =b sin</pre>
				<p>
					И наоборот:
				</p>
				<pre>sin =b (\x. sin x)</pre>
			</li>
		</ul>

		<p>
			После всего этого появляется интересный вопрос. Вот, например, выражение <code>succ 3</code> невычислимо в том смысле, что в результате применения &beta;-редукций получается терм-функция <code>\f. \x. f(f(f(f x)))</code>. Хотите получить самую-самую &beta;-нормальную форму и применить еще одну &beta;-редукцию? Удачи вычислить <code>f x</code> с применением переменной <code>f</code>.
		</p>

		<p>
			И как вообще определить, правда ли <code>succ 3</code> &mdash; это то же самое, что <code>4</code>? В теории можно использовать &beta;-эквивалентность, уже известную нам как отношение <code>=b</code>. Но хотелось бы научиться как-то конструктивно определять это.
		</p>

		<p>
			Делается это так: вычисляем оба сравниваемые выражения, проводя все возможные &beta;-редукции, которые можно, по нормальному порядку вычислений, даже если &beta;-редуцированные термы находятся внутри определений функций. После этого достаточно просто сравнить выражения на посимвольное равенство. Пример для понимания: <code>\a. \b. b ((\x. x x) a) = \a. \b. b (a a)</code>. Далее, термы <code>\x. \y. x y</code> и <code>\y. \x. y x</code> эквивалентны, хотя и не равны посимвольно &mdash; про &alpha;-эквивалентность забывать нельзя. Ну и как же не упомянуть замыкающее троицу &eta;-преобразование: <code>\f. \x. f x</code> и <code>\f. f</code> также должны быть эквивалентны.
		</p>

		<p>
			Однако в более сложных ситуациях при попытке применить этот метод всплывает некоторая проблема. Дело в том, что далеко не все термы имеют &beta;-нормальную форму. Например, <code>(\x. x x) (\x. x x)</code> &mdash; типичный пример "бесконечного цикла" в &lambda;-исчислении. В таком более общем случае задача конструктивной проверки &beta;-эквивалентности неразрешима, но об этом мы подробнее поговорим чуть позже.
		</p>


		<nav>
			<a href="pt2.html">&leftarrow; II. Управление поведением</a>
			<a href="pt4.html">IV. Продвинутая арифметика &rightarrow;</a>
		</nav>


		<script type="text/javascript" src="js/highlighting.js"></script>
	</body>
</html>
